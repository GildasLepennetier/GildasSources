#!/usr/bin/python
import sys,argparse

##########################################
# Load a fasta file - rough
def Fasta_To_Dico_path(path,idtag='>',eol="\n"):
	with open(path,'r') as file:
		dico={}
		for line in file:
			line=line.split(eol)[0]
			if line[0]==idtag:
				ID=line[1:] #avoid '>' in IDs
				dico[ID]='' 
			else:
				dico[ID]+=line
	return dico
# Load a fasta file - rough
def Fasta_To_Dico_file(file,idtag='>',eol="\n"):
	dico={}
	for line in file:
		line=line.split(eol)[0]
		if line[0]==idtag:
			ID=line[1:] #avoid '>' in IDs
			dico[ID]=''
		else:
			dico[ID]+=line
	return dico
# LOAD FASTA BIOPYTHON ####
def loadFasta(adresse,eol="\n"):
	from Bio import SeqIO
	dico={}
	for seq_record in SeqIO.parse(adresse, 'fasta'):
		ID=str(seq_record.description)
		SEQ=str( seq_record.seq.split(eol)[0] )
		if ID not in dico.keys():
			dico[ID]=SEQ
		else:
			print("ERROR: %s already exist as key!"%ID)
	return dico
# Load fasta biopython2
def loadFastaBiopython(path):
	from Bio import SeqIO
	return { k.split(' ')[0]:seq.split('\n')[0] for k,seq in SeqIO.to_dict(SeqIO.parse(path, 'fasta')).items() }
# Give the reverse complement of a DNA sequence, change also if iupac nucleotide ####
from string import maketrans
def revCompl_DNA(seq,intab="AaTtCcGgRrYySsWwKkMmBbVvDdHh",outtab="TtAaGgCcYyRrWwSsMmKkVvBbHhDd"):
	return seq.translate(maketrans(intab,outtab))[::-1]
# Give the translation in protein of a DNA sequence ####
def translate_dna(sequence, quiet=False, number='not given', id_fa='not given'):
	codontable = {
	'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',
	'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',
	'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',
	'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',
	'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',
	'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',
	'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',
	'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',
	'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',
	'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',
	'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',
	'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',
	'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',
	'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',
	'TAC':'Y', 'TAT':'Y', 'TAA':'', 'TAG':'',
	'TGC':'C', 'TGT':'C', 'TGA':'', 'TGG':'W',
	}
	#TAA, TAG and TGA can also be marked as _
	# we are in eukaryotes
	proteinsequence = ''
	for n in range(0,len(sequence),3):
		codon=sequence[n:n+3]
		if codon in codontable.keys():
			proteinsequence += codontable[codon]
		else:
			proteinsequence += "*"
			if not quiet:
				sys.stderr.write("Error, codon %s does not exist, will be replaced by a star '*' in protein sequence (number: %s, id: %s)\n"%(codon,number,id_fa))
	return proteinsequence
# insert in string, each X letter () perfect to format a fasta file with 80 nt per line
def insert_in_string(string,insert="\n",each=80):
	string2=""
	ii=0
	for letter in string:
		ii+=1
		if ii % each == 0 :
			string2=string2+letter
			string2=string2+insert
		else:
			string2=string2+letter
	return string2

# main 
if __name__ == '__main__':
	
	
	COMMANDES=['rc_dna', 'csv_to_fa', 'fa_to_csv', 'fa_freq', 'fa_extr_ids', 'fa_translate', 'fa_get','count','fa_split']


	##########################################
	parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter,description="""%(prog)s (- for stdin read) -cmd <command> <options>

-cmd <command>
	
	---------
	rc_dna	(reverse complement)
	
	---------
	csv_to_fa	(Conversion fasta to csv)
	
		-seqCol	specify the column where is the sequence
		-idCol	in which column are the ids, coma separated list
		-idJoin	allows to change the separator when several ids are used
		-header	if csv has an header
		-sep	to specify csv spacer (default is tab)
	
	---------
	fa_to_csv	(Conversion cvs to fasta)
	
		-rmId	allows to remove the id of the sequence
		-header	to add header with column names
		
	---------
	fa_freq	(calculate the nucleotid frequency)
	
	---------
	fa_extr_ids	(extract records by name)
	
		-id_file <file with one id per line>
		-id id1,id2
	
	---------
	fa_translate	(translate dna to protein, expect only full CDS)
	
		-rmTxErrors	check some basics errors: Start, premature stop, unknown codon
	---------
	fa_get	(extract records following rules)
	
		-rules should be provided, as VAR=value
		
		KEEP =integer	keep only the first (non-ordered) x records
		RANDOM =True or False	to get the sequence at random
		MAX_SEQ_LENGTH =integer	maximum length (default: none)
		MIN_SEQ_LENGTH =integer	minimum length (default: 0)
		
	---------
	count	(count the number of fasta records)
	
	---------
	fa_split	(split in several fasta files)
			
			Will be save in <file>_partx.fa
			incompatible with -out (not with stdout)
			
			-outputName to change file name pattern
			-f option to force overwrite

		MAX_SEQ_PER_FILE =integer	maximum record per file.
		DIVIDE_IN_MAX =integer	divide in this number of file maximum
		
	---------
	OTHER GLOBAL OPTIONS
	
	-CharPerLine	by befaut, fasta records are 80 char-long
	""",epilog='Author: Gildas Lepennetier: gildas.lepennetier@hotmail.fr')
	
	parser.add_argument('-in','-i',required=False,type=argparse.FileType('r'),default=sys.stdin, help='input file, (default stdin).')
	parser.add_argument('-out','-o',required=False,type=argparse.FileType('w'),default=sys.stdout, help='output file (default stdout)')
	parser.add_argument('-outputName',type=str,default='part.fa',help="pattern to name file, in the case of using MAX_SEQ_PER_FILE option. default: part0001.fa")
	parser.add_argument('-force','-f',action='store_true',help="use to overwrite existing files, in the case of using MAX_SEQ_PER_FILE option")
	parser.add_argument('-cmd',type=str,required=True,help="commande to execute, see description")
	parser.add_argument('-seqCol',type=int,required=False,help='sequence column index')
	parser.add_argument('-idCol',type=str,required=False,help='coma separated list for ids column index, see -idJoin for separator')
	parser.add_argument('-id_list',type=str,required=False,help='coma separated list for ids')
	parser.add_argument('-idJoin',type=str,default="_",required=False,help='If several columns for id, this will be the spacer. default: "_" ')
	parser.add_argument('-CharPerLine',type=int,default=80,required=False,help='number of char per line, default 80')
	parser.add_argument('-rmId',action='store_true',default=False,help='to remove fasta ids when csv conversion')
	parser.add_argument('-id_file',type=str,help='file with ids, one per line')
	parser.add_argument('-rmTxErrors',action='store_true',default=False,help='to check the translated sequence. Remove: not starting with M (ATG), premature stop in the cds (space in the sequence) or with unknown * codon')
	parser.add_argument('-rules',type=str,required=False,help='set of rules, ex: "RANDOM=True + MIN_SEQ_LENGTH = 200"')
	parser.add_argument('-printRules',action='store_true',help='print the rules on stderr and exit')
	parser.add_argument('-header',action='store_true',default=False,help='add this flag if you have/want an header (fist line with names of columns)')
	parser.add_argument('-eol',type=str,default='\n',required=False,help='end of line char (default: unix \\n)')
	parser.add_argument('-sep',type=str,default='\t',required=False,help='separator for csv file (default: tabulation \\t)')
	parser.add_argument('--version','-V', action='version', version='%(prog)s version 2.0')#version display
	parser.add_argument('--verbose', '-v', action='count',default=0,help='add flag(s) to increase verbosity')# count the level of verbosity, +1 for each -v flag
	parser.add_argument('--copy','-C',action='store_true',help='Display Copyright informations')
	parser.add_argument('--author','-A',action='store_true',help='Display author informations')
	
	args=vars(parser.parse_args())
	
	if args['author']:
		print ("LEPENNETIER Gildas - contact email: gildas.lepennetier@hotmail.fr")
		exit(0)
	if args['copy']:
		print ("Copyright 2014-2016 LEPENNETIER Gildas")
		exit(0)
	
	
	##########################################
	# checks and loading 
	if args['cmd'] not in COMMANDES:
		sys.stderr.write("Error, %s is not an available command\nuse -h to get help\navailable commands: %s\n"%(args['cmd'], ", ".join(COMMANDES) ) )
	
	#load the rules
	RULES={'RANDOM':'False','MIN_SEQ_LENGTH':'0','MAX_SEQ_LENGTH':'none','MAX_SEQ_PER_FILE':'all','DIVIDE_IN_MAX':'none'}
	if args['rules']:
		RULES_STRING=args['rules'].replace(' ','').split('+')
		for ru in RULES_STRING:
			Var = ru.split('=')[0]
			Val = ru.split('=')[1]
			RULES[Var]=Val #CAREFUL : rules are all in text!
	if args['printRules']:
		sys.stderr.write("Rules are set to:\n")
		for ru in RULES.keys():
			sys.stderr.write("%s\t%s\n"%(ru,RULES[ru]))
		exit(0)
	
	##########################################
	
	if args['cmd'] == 'rc_dna':
		DICO=Fasta_To_Dico_file(args['in'])
		for k in DICO.keys():
			args['out'].write(">%s\n%s\n"%(k, insert_in_string( revCompl_DNA(DICO[k], each=args['CharPerLine']) ) ))
	
	##########################################
	
	if args['cmd'] == 'count':
		k=0
		for line in args['in'].readlines():
			if args['header']:
				continue
			else:
				if line[0]=='>':
					k+=1
		args['out'].write("%s fasta_records\n"%k)
	
	##########################################
	
	if args['cmd'] == 'csv_to_fasta':
		if args['verbose'] > 0:
			sys.stderr.write("Info: starting csv_to_fasta\n")
		if not args['seqCol']:
			print ("Error: you should give a column number where the sequence is located")
		if not args['idCol']:
			print ("Error: you should give a column number where the id is located. Advice: check the each id is uniq, or give a coma sep list of clumn for the id")
		
		seqCol_index=args['seqCol'] -1 #python index starts at 0
		id_index=[ int(el)-1 for el in args['idCol'].split(',') ] #python index starts at 0
		k=0
		for rline in args['in']:
			k+=1
			if args['header'] and k==1:
				pass
			else:
				line=rline.split('\n')[0].split(args['sep'])
				
				ID= '>' + args['idJoin'].join([el for el in [ line[i] for i in id_index ] ]) + '\n'
				SEQ=insert_in_string(string=line[seqCol_index],insert='\n', each=args['CharPerLine']) # seq
				
				args['out'].write( ID + SEQ + '\n')
	
	##########################################
	
	if args['cmd'] == 'fa_to_csv':
		if args['header']:
			if not args['rmId']:
				args['out'].write("fasta_id" + args['sep'] + "sequence" + '\n' )
			else:
				args['out'].write("sequence" + '\n' )
		k=0
		for rline in args['in']:
			k+=1
			line=rline.split('\n')[0]
			if line:
				if not args['rmId']:
					if line[0] == '>':
						if k > 1:
							args['out'].write('\n')#need to go back to line, but not for first line
						ID=line.split('>')[1] # extract id
						args['out'].write(ID + args['sep'])
					else:
						args['out'].write(line) # print sequence
					
				else: #do not keep id
					if line[0] == '>':
						if k > 1:
							args['out'].write('\n')#need to go back to line, but not for first line
					else:
						args['out'].write(line) # print sequence
		args['out'].write('\n') #last line: should have that
	
	##########################################
	
	if args['cmd'] == 'fa_freq':
		COUNT={'A':0.0,'C':0.0,'G':0.0,'T':0.0,'N':0.0,'nb':0.0}
		for rline in args['in']:
			line=rline.split('\n')[0]
			if line:
				if line[0] != '>':
					COUNT['A'] += line.count("A") + line.count("a")
					COUNT['C'] += line.count("C") + line.count("c")
					COUNT['G'] += line.count("G") + line.count("g")
					COUNT['T'] += line.count("T") + line.count("t")
					COUNT['N'] += line.count("N") + line.count("n")
					COUNT['nb'] += len(line)
		FREQ=dict()
		for key in COUNT.keys():
			if key not in ['nb']:
				if COUNT[key] != 0:
					FREQ[key] = COUNT[key]/COUNT['nb']
		
		if FREQ['A']+FREQ['C']+FREQ['G']+FREQ['T'] !=1:
			TOT=FREQ['A']+FREQ['C']+FREQ['G']+FREQ['T']
			sys.stderr.write("Warning: total ACGT = %s ; N=%s%s"%(TOT,int(COUNT['N']),'\n'))
		#print (COUNT)
		args['out'].write( args['sep'].join ( [ str(el) for el in [ FREQ['A'],FREQ['C'],FREQ['G'],FREQ['T'] ] ] ) +'\n' )
	
	##########################################
	
	if args['cmd'] == 'fa_extr_ids':
		IDS=[]
		if not args['id_list'] and not args['id_file']:
			sys.stderr.write("Error: id missing, you need to specify ids to keep! : id_list or id_file options\n")
			exit(1)
		if args['id_list']:
			for i in args['id_list'].split(","):
				IDS.append(i)
		if args['id_file']:
			with open (args['id_file'], 'r') as f:
				for line in f.readlines():
					IDS.append( line.strip() )
		if args['verbose'] > 0:
			sys.stderr.write("%s ids to print\n"%(len(IDS) ))
			if args['verbose'] > 1:
				if len(IDS)>0:
					sys.stderr.write(",".join(IDS) + "\n" )
		p=False
		for line in args['in']:
			if line[0] == '>':
				
				current_ID=line.split('\n')[0].split(' ')[0].split('>')[1]
				if current_ID in IDS:
					if args['verbose'] > 2:
						sys.stderr.write("id %s will be saved\n"%(current_ID))
					p=True
				else:
					if args['verbose'] > 2:
						sys.stderr.write("id %s ignored\n"%(current_ID))
					p=False
			if p: #if we are still on the lines following an id
				args['out'].write(line)
	
	##########################################
	
	if args['cmd'] == 'fa_translate':
		k=0
		sequence = ''
		fasta_id = 'none'
		for line in args['in']:
			if line[0]=='>':
				k+=1
				if sequence:
					TXSEQ=translate_dna(sequence, args['quiet'], k, fasta_id)
					if args['rmTxErrors']:
						if TXSEQ[0] != 'M' or '*' in TXSEQ or ' ' in TXSEQ:
							TXSEQ=''
							if not args['quiet']:
								sys.stderr.write("-> removed %s\n"%(fasta_id))
					if TXSEQ:
						args['out'].write( insert_in_string( TXSEQ, each=args['CharPerLine'] ) + '\n' )
					
				#reinitialise
				fasta_id=line.split(" ")[0].split('>')[1].strip()
				args['out'].write( '>'+ fasta_id + '\n' )
				sequence = ''
				
			else:
				sequence += line.strip()
		if sequence:
			TXSEQ=translate_dna(sequence, args['quiet'], k, fasta_id)
			if args['rmTxErrors']:
				if TXSEQ[0] != 'M' or '*' in TXSEQ or ' ' in TXSEQ:
					TXSEQ=''
					if not args['quiet']:
						sys.stderr.write("-> removed %s\n"%(fasta_id))
			if TXSEQ:
				args['out'].write( insert_in_string( TXSEQ, each=args['CharPerLine']  ) + '\n' )
	
	##########################################
	
	if args['cmd'] == 'fa_get':
		DICO=Fasta_To_Dico_file(args['in']) # no keep of skip : dico do not preserve order
		IDS_PASS=[]
		for ID in DICO.keys():
			#test on size
			if len(DICO[ID]) >= int(RULES['MIN_SEQ_LENGTH']):
				if RULES['MAX_SEQ_LENGTH'] == 'none':
					IDS_PASS.append(ID)
				else:
					if len(DICO[ID]) <= int(RULES['MAX_SEQ_LENGTH']):
						IDS_PASS.append(ID)
		
		if RULES['KEEP'] == 'all':
			maxi=len(DICO.keys())+1
		else:
			maxi=int(RULES['KEEP'])+1
		
		
		if RULES['RANDOM'].upper() == 'TRUE':
			import random
			random.shuffle(IDS)
		
		k=0
		for ID in IDS_PASS:
			k+=1
			if k == maxi:
				exit(0)
			else:
				args['out'].write(">%s\n%s\n"%(ID,insert_in_string(DICO[ID],each=args['CharPerLine'])))
				
	
	##########################################
	
	if args['cmd'] == 'fa_split':
		import os
		DICO=Fasta_To_Dico_file(args['in'])
		NBRECORDS=len(DICO.keys())
		if RULES['DIVIDE_IN_MAX'] == 'none':
			NBFILESMAX=NBRECORDS
		else:
			NBFILESMAX=int(RULES['DIVIDE_IN_MAX'])
		#check required number of files
		if RULES['MAX_SEQ_PER_FILE'] == 'all':
			MAXPERFILE=NBRECORDS
			REQUIRED=1
		else:
			MAXPERFILE=int(RULES['MAX_SEQ_PER_FILE'])
			if NBRECORDS % MAXPERFILE != 0:
				REQUIRED = NBRECORDS / MAXPERFILE +1
			else:
				REQUIRED = NBRECORDS / MAXPERFILE
		#if not enough files planned
		if NBFILESMAX < REQUIRED:
			sys.stderr.write("ERROR: you asked for %s files with max %s record(s), but %s files is/are required for your %s record(s)\n"%(NBFILESMAX,MAXPERFILE,REQUIRED,NBRECORDS))
			exit(1)
		if args['verbose'] > 0:
			sys.stderr.write("INFO: you asked for %s files with max %s record(s), and %s files is/are required for your %s record(s)\n"%(NBFILESMAX,MAXPERFILE,REQUIRED,NBRECORDS))
		SUFFIX=range(1,REQUIRED+1)#+1 for proper range
		
		PATH=os.path.dirname(args['outputName'])
		if not PATH:
			PATH="."
		BASENAME=os.path.basename(args['outputName'])
		EXTENSION="fa"
		SPLIT=BASENAME.split('.')
		if len(SPLIT) > 1:
			BASENAME = "".join(SPLIT[:len(SPLIT)-1])
			EXTENSION=SPLIT[len(SPLIT)-1]
		Signif = len(str(REQUIRED)) #number of leading zeros required
		FILENAMES=[]
		for Suffix in SUFFIX:
			#check if existing
			FILENAME=PATH + "/" + BASENAME + '%0*d'%(Signif, Suffix) + "." + EXTENSION
			if os.path.isfile(FILENAME) and not args['force']:
				sys.stderr.write("ERROR: file exist, use the -force option to overwrite\n")
				sys.stderr.write("file is: %s\n"%FILENAME)
				exit(1)
			else:
				FILENAMES.append(FILENAME)
		
		if len(FILENAMES) > 20:
			sys.stderr.write("WARNING: you will create %s files\n"%len(FILENAMES))
			response = raw_input("Please type 'yes' to confirm: ")
			if response != 'yes':
				sys.stderr.write("cancelled\n")
				exit(1)
		# now need to open each file and print the proper number of records on it
		k_tot_record=0
		k_record=0
		k_name=0
		
		if args['verbose'] > 0:
			sys.stderr.write("open %s\n"%FILENAMES[k_name])
		myfile = open(FILENAMES[k_name], 'w')
		
		
		for ID in DICO.keys():
			k_record+=1
			k_tot_record+=1
			myfile.write(">%s\n%s\n"%(ID,insert_in_string(DICO[ID],each=args['CharPerLine'])))
			
			if k_tot_record == NBRECORDS:
				if args['verbose'] > 0:
					sys.stderr.write("reached %s records\n"%NBRECORDS)
					sys.stderr.write("close %s\n"%FILENAMES[k_name])
				myfile.close()
				exit(0)
				
			if k_record == MAXPERFILE:
				if args['verbose'] > 0:
					sys.stderr.write("%s record printed\n"%k_record)
					sys.stderr.write("close %s\n"%FILENAMES[k_name])
				k_record=0
				myfile.close()
				
				k_name+=1
				if args['verbose'] > 0:
					sys.stderr.write("open %s\n"%FILENAMES[k_name])
				myfile = open(FILENAMES[k_name], 'w')
				
		if args['verbose'] > 0:
			sys.stderr.write("%s record printed\n"%k_record)
			sys.stderr.write("close %s\n"%FILENAMES[k_name])
		myfile.close()

